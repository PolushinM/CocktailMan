{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d460565",
   "metadata": {},
   "source": [
    "### Сщздание ONNX \"модели\", выполняющей размытие изображения по маске."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1100,
   "id": "efc23343",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import json\n",
    "from typing import Tuple\n",
    "import math\n",
    "\n",
    "from glob import glob\n",
    "from tqdm.notebook import tqdm\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "from openvino.runtime import Core\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import clear_output\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "sns.set(style='darkgrid', font_scale=1.2)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(device)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3546b5aa",
   "metadata": {},
   "source": [
    "Загружаем изображение для визуализации:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 949,
   "id": "14bee61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = \"/home/maksim/Downloads/1440355628_gavajskij-koktejl-potok-lavy.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a667e52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.open(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1426,
   "id": "9630524c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 820, 616])"
      ]
     },
     "execution_count": 1426,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = Image.open(img_path).convert(\"RGB\")\n",
    "img = img.resize((img.size[0]//2*2, img.size[1]//2*2))\n",
    "image = np.asarray(img) / 255\n",
    "image = torch.tensor(np.moveaxis(image, 2, 0), dtype=torch.float32)[None, ...]\n",
    "image.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df1ac1b9",
   "metadata": {},
   "source": [
    "Функция для расчета маски размытия по координатам bounding box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1427,
   "id": "58accc8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def __generate_blur_mask(size: Tuple[int, int], b_box: Tuple[float, float, float, float]) -> np.array:\n",
    "    height, width = size\n",
    "    y_min, x_min, y_max, x_max = b_box\n",
    "\n",
    "    x_min, x_max = round(x_min * width), round(x_max * width)\n",
    "    y_min, y_max = round(y_min * height), round(y_max * height)\n",
    "\n",
    "    result = np.zeros((width, height), dtype=np.float32)\n",
    "\n",
    "    x = np.linspace(x_min/width, 0, x_min)\n",
    "    y = np.linspace(y_min/height, 0, y_min)\n",
    "    yv, xv = np.meshgrid(y, x)\n",
    "    box1 = (1 / ((xv ** 2 + yv ** 2) ** 0.5 + 1)).astype(np.float32)\n",
    "\n",
    "    box2 = 1 / (np.full((x_max - x_min, y_min), np.linspace(y_min/height, 0, y_min)) + 1)\n",
    "\n",
    "    x = np.linspace(0, (width - x_max)/width, width - x_max)\n",
    "    y = np.linspace(y_min/height, 0, y_min)\n",
    "    yv, xv = np.meshgrid(y, x)\n",
    "    box3 = (1 / ((xv ** 2 + yv ** 2) ** 0.5 + 1)).astype(np.float32)\n",
    "\n",
    "    box4 = 1 / (np.full((y_max - y_min, width - x_max), np.linspace(0, (width - x_max)/width, width - x_max)) + 1).T\n",
    "\n",
    "    x = np.linspace(0, (width - x_max)/width, width - x_max)\n",
    "    y = np.linspace(0, (height - y_max)/height, height - y_max)\n",
    "    yv, xv = np.meshgrid(y, x)\n",
    "    box5 = (1 / ((xv ** 2 + yv ** 2) ** 0.5 + 1)).astype(np.float32)\n",
    "\n",
    "    box6 = 1 / (np.full((x_max - x_min, height - y_max), np.linspace(0, (height - y_max)/height, height - y_max)) + 1)\n",
    "\n",
    "    x = np.linspace(x_min/width, 0, x_min)\n",
    "    y = np.linspace(0, (height - y_max)/height, height - y_max)\n",
    "    yv, xv = np.meshgrid(y, x)\n",
    "    box7 = (1 / ((xv ** 2 + yv ** 2) ** 0.5 + 1)).astype(np.float32)\n",
    "\n",
    "    box8 = 1 / (np.full((y_max - y_min, x_min), np.linspace(x_min/width, 0, x_min)) + 1).T\n",
    "\n",
    "    result[x_min: x_max, y_min: y_max] = 1.0\n",
    "\n",
    "    result[0: x_min, 0: y_min] = box1\n",
    "    result[x_min: x_max, 0: y_min] = box2\n",
    "    result[x_max:, 0: y_min] = box3\n",
    "    result[x_max:, y_min: y_max] = box4\n",
    "    result[x_max:, y_max:] = box5\n",
    "    result[x_min: x_max, y_max:] = box6\n",
    "    result[0: x_min, y_max:] = box7\n",
    "    result[0: x_min, y_min: y_max] = box8\n",
    "    \n",
    "\n",
    "    return result[None, None, :, :]**2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f580e5ba",
   "metadata": {},
   "source": [
    "Pytorch \"Модель\". Содержит свертку с Гауссовым ядром, выполняющую размывание, свертки для уменьшения и увеличения размера изображения для ускорения работы, наложение размытых изображений и исходного изображения по маске."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1450,
   "id": "1d4dbcf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Blur(nn.Module):\n",
    "    def __init__(self, kernel_size):\n",
    "        super(Blur, self).__init__()\n",
    "        self.blur = nn.Conv2d(3, 3, kernel_size=kernel_size, stride=1, padding=kernel_size//2, bias=False, padding_mode='replicate')\n",
    "        self.zip = nn.Conv2d(4, 4, kernel_size=2, stride=2, bias=False)\n",
    "        self.unzip =  nn.ConvTranspose2d(3, 3, kernel_size=2, stride=2, bias=False)\n",
    "        \n",
    "        # Gaussian blur kernels\n",
    "        k0 = torch.zeros((1, 1, kernel_size, kernel_size), dtype=torch.float32)\n",
    "        k1 = torch.tensor(self.calc_gaussian_kernel(kernel_size, kernel_size*1.25), dtype=torch.float32)[None, None, :, :]\n",
    "        kernel = torch.cat((torch.cat((k1, k0, k0), dim=1),\n",
    "                 torch.cat((k0, k1, k0), dim=1),\n",
    "                 torch.cat((k0, k0, k1), dim=1)))\n",
    "        for i in range(kernel.shape[0]):\n",
    "            self.state_dict()['blur.weight'][i] = kernel[i]\n",
    "\n",
    "        # Zip kernels\n",
    "        k0 = torch.zeros((1, 1, 2, 2), dtype=torch.float32)\n",
    "        k1 = torch.ones((1, 1, 2, 2), dtype=torch.float32) * 0.25\n",
    "        kernel = torch.cat((torch.cat((k1, k0, k0, k0), dim=1),\n",
    "                 torch.cat((k0, k1, k0, k0), dim=1),\n",
    "                 torch.cat((k0, k0, k1, k0), dim=1),\n",
    "                 torch.cat((k0, k0, k0, k1), dim=1)))\n",
    "        for i in range(kernel.shape[0]):\n",
    "            self.state_dict()['zip.weight'][i] = kernel[i]\n",
    "            \n",
    "        # Unzip cernels\n",
    "        k0 = torch.zeros((1, 1, 2, 2), dtype=torch.float32)\n",
    "        k1 = torch.ones((1, 1, 2, 2), dtype=torch.float32)\n",
    "        kernel = torch.cat((torch.cat((k1, k0, k0), dim=1),\n",
    "                 torch.cat((k0, k1, k0), dim=1),\n",
    "                 torch.cat((k0, k0, k1), dim=1)))\n",
    "        for i in range(kernel.shape[0]):\n",
    "            self.state_dict()['unzip.weight'][i] = kernel[i]\n",
    "            \n",
    "        \n",
    "    def calc_gaussian_kernel(self, size: int, fwhm: float) -> np.array:\n",
    "        \"\"\" Make a square gaussian kernel.\n",
    "\n",
    "        size is the length of a side of the square\n",
    "        fwhm is full-width-half-maximum, which\n",
    "        can be thought of as an effective radius.\n",
    "        \"\"\"\n",
    "        x = np.arange(0, size, 1, float)\n",
    "        y = x[:,np.newaxis]\n",
    "        x0 = y0 = size // 2\n",
    "        kernel = np.exp(-4*np.log(2) * ((x-x0)**2 + (y-y0)**2) / fwhm**2)\n",
    "        return kernel / kernel.sum()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        initial = x[:, :3, :, :]\n",
    "        mask = x[:, 3:4, :, :]\n",
    "        x_zip = self.zip(x)\n",
    "        blured_zip = x_zip[:, :3, :, :]\n",
    "        initial_zip = x_zip[:, :3, :, :]\n",
    "        mask_zip = x_zip[:, 3:4, :, :]\n",
    "        \n",
    "        blured_1_zip = self.blur(blured_zip)\n",
    "        \n",
    "        blured_2_zip = blured_1_zip * (1-mask_zip) + initial_zip * mask_zip\n",
    "        \n",
    "        blured_2_zip = self.blur(blured_2_zip)\n",
    "            \n",
    "        blured_3_zip = blured_2_zip * (1-mask_zip**3) + initial_zip * mask_zip**3\n",
    "        \n",
    "        for i in range(2):\n",
    "            blured_3_zip = self.blur(blured_3_zip)\n",
    "            \n",
    "        blured_4 = self.unzip(blured_3_zip) * (1-mask**9) + initial * mask**9\n",
    "\n",
    "        return blured_4\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1459,
   "id": "d540ddc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "KERNEL_SIZE = 17\n",
    "model = Blur(KERNEL_SIZE).to('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "367fb927",
   "metadata": {},
   "source": [
    "Проверяем работу:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1461,
   "id": "90f9d360",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.42610756\n"
     ]
    }
   ],
   "source": [
    "mask = __generate_blur_mask((image.shape[3], image.shape[2]), (0.35, 0.4, 0.7, 0.95))\n",
    "blured_image = model(torch.tensor(np.concatenate((image, mask), axis=1))).detach().numpy()\n",
    "print(mask.min())"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3c9ca9ce",
   "metadata": {},
   "source": [
    "plt.figure(figsize=(12, 20))\n",
    "plt.imshow(np.moveaxis(blured_image[0], 0, 2))\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7830161f",
   "metadata": {},
   "source": [
    "#### Конвертация в ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1463,
   "id": "87c16d97",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied.\n",
      "Warning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied.\n",
      "Warning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied.\n",
      "Warning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied.\n",
      "Warning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied.\n",
      "Warning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied.\n",
      "Warning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied.\n",
      "Warning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied.\n",
      "Warning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied.\n",
      "Warning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied.\n",
      "Warning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied.\n",
      "Warning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied.\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model to switch some operations from training mode to inference.\n",
    "model.eval()\n",
    "# Create dummy input for the model. It will be used to run the model inside export function.\n",
    "dummy_input = torch.randn(1, 4, 320, 320)\n",
    "# Call the export function\n",
    "torch.onnx.export(model,\n",
    "                  args=dummy_input,\n",
    "                  f='blur.onnx',\n",
    "                  export_params=True,\n",
    "                  opset_version=11,\n",
    "                  do_constant_folding=True,\n",
    "                  input_names = ['image'],\n",
    "                  output_names = ['output'],\n",
    "                  dynamic_axes={'image' : {2: 'width', 3: 'height'},\n",
    "                                'output' : {2: 'width', 3: 'height'}})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d0856b8",
   "metadata": {},
   "source": [
    "Проверяем инференс на OpenVino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1464,
   "id": "c66332ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "ie = Core()\n",
    "onnx_model_path = 'blur.onnx'\n",
    "model_onnx = ie.read_model(model=onnx_model_path)\n",
    "compiled_model_onnx = ie.compile_model(model=model_onnx, device_name=\"CPU\")\n",
    "\n",
    "input_layer = compiled_model_onnx.input(0)\n",
    "output_layer = compiled_model_onnx.output(0)\n",
    "infer_request = compiled_model_onnx.create_infer_request()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1465,
   "id": "5d85173d",
   "metadata": {},
   "outputs": [],
   "source": [
    "input = np.concatenate((image, mask), axis=1)\n",
    "blured_image = infer_request.infer([input])[output_layer][0]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8ff322f0",
   "metadata": {},
   "source": [
    "plt.imshow(np.rollaxis(blured_image, 0, 3))\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd307336",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb32c739",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddfcafc6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2050758d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849c4aab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f1e876",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c63de9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
